{"name":"An approach to classify the races of characters from Lord of the Rings using their names as feature and naive Bayes","tagline":"Machine learning used to classify the race of characters from Lord of the Rings","body":"# An approach to classify the races of characters from Lord of the Rings using their names as feature and naive Bayes\r\n\r\n## Overview\r\n***\r\nAs a huge fan of the Lord of the Rings and Tolkien's work, I was interested in finding a way of using data from the legendarium with machine learning. While searching and pondering about what problem could be interesting, I had the idea of playing around with the names of the characters and the relation to the race of said character.\r\n\r\nIn this report, I will discuss and show an approach used to predict the races of the characters from Lord of the Rings using a naive Bayes classifier and various techniques for natural language processing. How is that done? You might ask. The reasoning behind this, is that an algorithm will be trained using the names of the characters and their races. While it is being trained, it will learn about the similarities between the names and the races. For example, suppose that we tell to the algorithm that the name `Juan`, `Jose` and `Jony` are Spanish names, in other words we are teaching the model that a name that starts with `J`, and has four characters is indeed a Spanish name. After the model is train, we feed it with the name `Javi` and if the training was successful, the algorithm will output that the name is a Spanish one. The dataset used consists of 827 observations (characters) and their respective race.\r\n\r\n### Data fields\r\n- name: the name of the character\r\n- race: the race of the character. There are five possible races: Man, Ainur, Elf, Dwarf and Hobbit.\r\n\r\n### Tools used\r\n- Spark (Pyspark)\r\n- R: for scraping, transforming and preparing the data.\r\n\r\n## Scraping the data\r\n***\r\nThe data used for the study was scraped from the website http://lotrproject.com/ (which is awesome). At the moment of writing, the homepage of the site features a family tree of all the characters from Tolkien's universe. Using Chrome's *View Page Source*, I copied the HTML code that is related to the characters to a new file.\r\n\r\nThen using R and the [rvest](https://cran.r-project.org/web/packages/rvest/rvest.pdf) web scraping library, I was able to scrap the wanted data. The next piece of code shows this.\r\n\r\n```r\r\nlibrary(rvest)\r\nhtml_data <- read_html(\"~/Development/lotr-names-classification/lotr-names-html.html\")\r\ncharacters_data <- data.frame(name = character(0), race = character(0),\r\n                              stringsAsFactors = FALSE)\r\n\r\nfor (i in 1:952){\r\n  \r\n  # Get the name\r\n  name <- html_data %>%\r\n    html_nodes(paste0('#', i)) %>%\r\n    html_text()\r\n  \r\n  race_and_class <- strsplit(html_data %>%\r\n    html_nodes(paste0('#', i)) %>%\r\n    html_attr('class'), split = ' ')\r\n  \r\n  if (length(name) > 0) {\r\n    characters_data[i,] <- list(name, race_and_class[[1]][length(race_and_class[[1]]) - 1])\r\n  }\r\n}\r\n```\r\nNow, we have the data in a dataframe (a table structure; think of an Excel worksheet). However, we are not done yet! As usual, the data is not in the right shape. Some of the observations has `?` as the character name, NA entries and trailing spaces (white spaces after the end of the word). So, let's clean.\r\n\r\n```r\r\n# Remove rows with NA\r\ncharacters_data <- na.omit(characters_data)\r\n# Remove rows where name is '?'\r\ncharacters_data <- characters_data[grep('\\\\?', characters_data$name, invert = TRUE), ]\r\n# Remove \\n from the names\r\ncharacters_data$name <- sub('\\n', '', characters_data$name)\r\n# Remove the prefix '1st', '2nd', etc.\r\ncharacters_data$name <- sub('[0-9]?[0-9][a-z]{2}', '', characters_data$name)\r\n```\r\n\r\nIn the previous piece of code, we removed rows that contains NA, character names `?`, and the prefix `1st`, `2nd`, etc that was present on some of the names. If you take a look at the linked website, you will see why the data has this.\r\n\r\nWhile cleaning the data, I removed those characters whose respective races does not appear often in the dataset because they would probably do more harm than good at the time of predicting since we do not have a large number of characters from that race.\r\n\r\n```r\r\n# Subset the races that have a significant number of entries\r\ncharacters_data <- characters_data[characters_data$race == 'Ainur' | \r\n                        characters_data$race == 'Dwarf' |\r\n                        characters_data$race == 'Elf' |\r\n                        characters_data$race == 'Half-elf' |\r\n                        characters_data$race == 'Hobbit' |\r\n                        characters_data$race == 'Man', ]\r\n# Change the half-elves for elves (sorry Elrond)\r\ncharacters_data$race[characters_data$race == 'Half-elf'] <- 'Elf'\r\n```\r\n\r\n![Table](http://juandes.github.io/lotr-names-classification/images/races_table.png)\r\n\\*the name with the strange characters should say *Dunedain*\r\n\r\nSo we kept, the ainur, dwarves, men, hobbits, elves and half-elves. These last two groups were merge into one, called elf.\r\n\r\nLastly, the trailing spaces were removed, as well to some characters who do not have an actual name, but a title, e.g. Master of Lake-town, and the surnames, e.g. Frodo Baggins -> Frodo and Thorin III -> Thorin.\r\n\r\n```r\r\n# Remove trailing spaces\r\ncharacters_data$name <- sub('[ \\t]+$', '', characters_data$name)\r\n# Remove an entry where the name is 'Others'\r\ncharacters_data <- characters_data[characters_data$name != 'Others' & \r\n                                     characters_data$name != 'Master of La...', ]\r\n\r\n# The names of the characters on this dataframe won't have any surnames or\r\n# numbers on their name; we'll keep just the first name.\r\ncharacters_no_surnames <- characters_data\r\n\r\n# Regex to remove everything after the first whitespace\r\ncharacters_no_surnames$name <- sub(' .*', '', characters_no_surnames$name)\r\n```\r\n\r\nThen the data was exported to a text file. In addition to the dataset without surnames, I also included a second dataset with the full name of the character.\r\n\r\n```r\r\nwrite.csv(characters_no_surnames, file = 'characters_no_surnames.csv', row.names = FALSE)\r\nwrite.csv(characters_data, file = 'characters_data.csv', row.names = FALSE)\r\n```\r\n\r\n## Model development and prediction\r\n***\r\n### Loading and pre-processing of data\r\nNow that we have the data, lets start the actual analysis in Spark. We will start by loading the data.\r\n\r\n```python\r\n# Import both the train and test dataset and register them as tables\r\nimported_data = sqlContext.read.format('com.databricks.spark.csv').options(\r\n    header='true') \\\r\n    .load('/Users/Juande/Development/lotr-names-classification/characters_no_surnames.csv')\r\n```\r\n\r\nBecause the data was exported from R as a CSV file, we need to load it as a CSV. Luckily for us, there is a package for Spark that handles this, [spark-csv](http://spark-packages.org/package/databricks/spark-csv).\r\n\r\nOnce the data is loaded, the next action is to create an RDD (a structure that holds the data) made of four columns. These are:\r\n- **complete_name**: the name of the character, e.g. Aragorn\r\n- **name** : name of the character (in lower case) as a list of characters, e.g. ['a','r','a','g','o','r','n']\r\n- **race**: race of the character, as a number; 0.0 for man, 1.0 for ainur, 2.0 for elf, 3.0 for hobbit and 4.0 for dwarf.\r\n- **length**: number of characters in the name. This feature is not used for the prediction, but we'll see at the end of the report.\r\n\r\n```python\r\n# Map the race to a number\r\nrace_to_number = {'Man': 0.0, 'Ainur': 1.0, 'Elf': 2.0, 'Hobbit': 3.0, 'Dwarf': 4.0}\r\n\r\n# Build a new rdd made of a row that has the name of the character, the name as a list of the characters, the race of\r\n# the character and the length of the name (this might be used later)\r\ndata_rdd = imported_data.map(lambda row: Row(complete_name=row.name, name=list(row.name.lower()),\r\n                                             race=race_to_number[row.race], length=len(row.name)))\r\ndf = sqlContext.createDataFrame(data_rdd)\r\n```\r\n\r\n### Transformation pipeline\r\n\r\nOne of the reason why I did this work, was to test Spark's ML pipeline. Normally, I used the MLLIB library for performing machine learning, but for this work I wanted to try ML and its pipeline for the first time. A pipeline is a sequence of stages where the data is transformed at each step. For more details of this, check the official documentation at [Spark's pipeline](http://spark.apache.org/docs/latest/ml-guide.html#pipeline). You might be asking why we need to transform the names, and the reason is that with this kind of problems (natural language processing), is not always optimal to use the text as it is. Normally, you have to transform it in such as way that it is better for the algorithms to process it.\r\n\r\nThe pipeline used for transforming the data consists of 3 steps:\r\n- *n-gram*: *n-gram is a contiguous sequence of n items from a given sequence of text or speech.* ([NGram](https://en.wikipedia.org/wiki/N-gram)). In this case, the items are the characters of the name. For this problem, I used an ngran with *n=2*, also known as a bigram.\r\n- *HashingTF*: Hashing trick or HashingTF (as it is called in Spark) is a technique used for turning features into indices of a vector. In other words, what we are doing with this transformation, is turning each item of the bigram into a number.\r\n- *IDF*: Inverse document frequency (IDF) is a technique used to deduct how important a bigram (in this case, typically it is a word) is to a document. This IDF number increased proportionally to the number of times a bigram appears in the document, or corpus. This transforming along with HashingTF are known as TF-IDF.\r\n\r\nTo explain the pipeline, let's use the name 'aragorn' as an example. Don't worry about the meaning of the numbers, the purpose of this example is to illustrate the process.\r\n\r\n`aragorn` -> apply n-gram -> `['a r', 'r a', 'a g', 'g o', 'o r', 'r n']` -> apply HashingTF -> `[86, 143, 156, 277, 312, 323]` -> apply IDF -> `[2.6586, 2.3246, 2.8272, 1.8987, 3.5835, 1.5832]`\r\n\r\n```r\r\n# Pipeline consisting of three stages: NGrams, HashingTF and IDF\r\nngram = NGram(n=2, inputCol=\"name\", outputCol=\"nGrams\")\r\nhashingTF = HashingTF(numFeatures=500, inputCol=\"nGrams\", outputCol=\"TF\")\r\nidf = IDF(inputCol=\"TF\", outputCol=\"idf\")\r\npipeline = Pipeline(stages = [ngram, hashingTF, idf])\r\n\r\n# Fit the pipeline \r\npipelined_data = pipeline.fit(df)\r\ntransformed_data = pipelined_data.transform(df)\r\ntraining_set, test_set = transformed_data.randomSplit([0.8, 0.2], seed = 10)\r\n```\r\n\r\nOnce the data is transformed, the dataset is split into a training set made of 80% of the original dataset, and a test set made of the remaining 20%.\r\n\r\n### Overview of the data\r\n\r\nBefore going into the actual prediction section, I would like to show some of the data so you can see it for yourself and reach your own conclusions about the similarities between the names (if there is one). When looking at it, think of the example of the Spanish names explained at the start.\r\n\r\n| Man           | Ainur         | Elf      | Hobbit      |   Dwarf  |\r\n| ------------- |:-------------:| --------:| ----------- | -------- |\r\n| Aragorn       | Manwë         | Arwen    |  Frodo      | Durin    |\r\n| Aulendil      | Aulë          | Ingwë    |  Ferumbras  | Óin      |\r\n| Atanalcar     | Oromë         | Ingil    |  Fortinbras | Thráin   |\r\n| Vardamir      | Irmo          | Galadriel|  Isembard   | Thorin   |\r\n| Axantur       | Morgorh       | Celeborn |  Flambard   | Glóin    |\r\n\r\nNotice any similarities between the races? What do you think? Remember the length feature I defined earlier? Let's see the average\r\nlength of names per race.\r\n\r\n```python\r\ndf.groupBy('race').agg({'length': 'avg'}).show()\r\n```\r\n\r\n|    Race       | Length        | \r\n| ------------- |:-------------:| \r\n| Man           | 7.13842482    | \r\n| Ainur         | 5.97368421    | \r\n| Elf           | 6.55855855    | \r\n| Hobbit        | 6.37142857    | \r\n| Dwarf         | 4.75510204    |\r\n\r\nThe table shows that on average, men has the longest names, e.g. Atanalcar, while dwarves have the shortest ones (heh!), e.g. Óin.\r\n\r\nNow, to the prediction model.\r\n\r\n## Prediction and results\r\n\r\nThe prediction model used in this report is a naive Bayes classifier. In most cases, this classifier performs well while working with text data because of it assumes that attributes values are independent of each other. But wait? If we are trying to predict the races based on the format of the name, why this? Good question. For these kind of problems the terms are conditionally dependent on each other, but let's not think about that.\r\n\r\nIn the next piece of code, the model is created, trained and tested using the test dataset. After that, we calculate the accuracy which is 0.801282051282 or roughly 80%.\r\n```python\r\n# Create the model, train and predict\r\nnb = NaiveBayes(smoothing=1.0, modelType=\"multinomial\", featuresCol='idf', labelCol='race')\r\nmodel = nb.fit(training_set)\r\npredictions = model.transform(test_set)\r\naccuracy = 1.0 * predictions.filter(predictions.race == predictions.prediction).count() / predictions.count()\r\nprint (accuracy)\r\n```\r\n\r\n80% is a good number! It means that in 8 out of 10 cases the model was able to guess correctly the race of the character. Better than random guessing, eh?\r\n\r\n## Conclusion\r\n***\r\nIn this report we built a naive Bayes classifier model for classifying the races of characters of Lord of the Rings based on their name. While doing it, topics such as classification, pipeline, and data pre-processing were discussed.\r\n\r\nWhat now? While the result of the algorithm was a good one, I am sure that the accuracy percentage can be improved at least by a few percentages. Our model was based on the bigram of the name, however certain features such as the length of the name, the ratio between vowels/consonants, and the number of foreign letters should be analyzed.\r\n\r\nTolkien was a genius.","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}